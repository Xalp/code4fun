# Set the environment variables first before running the command.
export HF_ALLOW_CODE_EVAL=1
export HF_DATASETS_TRUST_REMOTE_CODE=true
export TORCHDYNAMO_DISABLE=1


task=mbpp
length=512
block_length=32
num_fewshot=3
steps=$((length / block_length))
factor=1.0
model_path='/pfs/training-data/wanglei/models/LLaDA-8B-Instruct'
# You can change the model path to LLaDA-1.5 by setting model_path='GSAI-ML/LLaDA-1.5'


# cache baseline 
# accelerate launch --main_process_port 29512 eval_llada.py --tasks ${task} --num_fewshot ${num_fewshot} \
# --confirm_run_unsafe_code --model llada_dist \
# --model_args model_path=${model_path},gen_length=${length},steps=${length},block_length=${block_length},use_cache=True,temperature=1.0,use_smc=True,show_speed=True 

# cache+parallel
accelerate launch --main_process_port 29514 eval_llada.py --tasks ${task} --num_fewshot ${num_fewshot} \
--confirm_run_unsafe_code --model llada_dist \
--model_args model_path=${model_path},gen_length=${length},steps=${steps},block_length=${block_length},use_cache=True,threshold=0.9,temperature=1.0,use_smc=False,show_speed=True 
